{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Geothermal Well Test Analysis with Python\n",
    "### Notebook 2: Temperature log data extraction and interpretation\n",
    "#### Irene Wallis and Katie McLean \n",
    "#### Software Underground, Transform 2021\n",
    "***\n",
    "\n",
    "# 4. Introduction to temperature logs\n",
    "\n",
    "Given that geothermal development seeks to mine heat energy from the Earth, temperature logs are arguably the most important data we acquire. In this tutorial, we will give a short introduction to handling these data and how they are interpreted.\n",
    "\n",
    "## 4.1 Uses of temperature logs in geothermal exploration and development\n",
    "\n",
    "- Feed zone identification\n",
    "- Interpreting well/reservoir events (e.g., heating after drilling or the initiation of a cool reservoir down flow)\n",
    "- Constraining conceptual models (natural state temperature profiles)\n",
    "- Calibrating reservoir models\n",
    "\n",
    "## 4.2 Key considerations when evaluating temperature data\n",
    "\n",
    "- The well status (shut, injection, flowing) while the log was acquired \n",
    "- When the temperature log was acquired (e.g., the time that has elapsed since drilling or since the well was flowed) \n",
    "- The thermodynamic conditions inside the well (liquid, two-phase, steam, cold gas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Google Colab Setup\n",
    "\n",
    "If you are using Google Colab to run this notebook, we assume you have already followed the Google Colab setup steps outlined [here](https://github.com/ICWallis/T21-Tutoral-WellTestAnalysis).\n",
    "\n",
    "Because we are importing data, we need to \"mount your Google Drive\", which is where we tell this notebook to look for the data files. You will need to mount the Google Drive into each notebook.  \n",
    "\n",
    "1. Run the cell below. If you are not in Google Colab, running the cell below will just return an error that says \"No module named 'google'\"\n",
    "\n",
    "2. Follow the link generated by running this code. That link will ask you to sign in to your google account (use the one where you have saved these tutorial materials in) and to allow this notebook access to your google drive. \n",
    "\n",
    "3. Completing step 2 above will generate a code. Copy this code, paste below where it says \"Enter your authorization code:\", and press ENTER. \n",
    "\n",
    "Congratulations, this notebook can now import data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# 5. Extract a completion test temprature log\n",
    "\n",
    "## 5.1 Use functions to import and munge the PTS and pump data\n",
    "\n",
    "Install packages required for this notebook. If you do not already have iapws in your environment, then you will need to pip install it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install iapws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iapws # steam tables\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from ipywidgets import interactive, Layout, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data munging process in 1-overview.ipynb has been turned into specilised functions. The cell below contains a set of helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_flowrate(filename):\n",
    "    ''' \n",
    "    Read PTS-2-injection-rate.xlsx in as a pandas dataframe and munge for analysis\n",
    "\n",
    "    args: filename is r'PTS-2-injection-rate.xlsx'\n",
    "\n",
    "    returns: pandas dataframe with local NZ datetime and flowrate in t/hr\n",
    "    '''\n",
    "    df = pd.read_excel(filename, header=1) \n",
    "    df.columns = ['raw_datetime','flow_Lpm']\n",
    "\n",
    "    list = []\n",
    "    for date in df['raw_datetime']:\n",
    "        newdate = datetime.fromisoformat(date)\n",
    "        list.append(newdate)\n",
    "    df['ISO_datetime'] = list \n",
    "\n",
    "    list = []\n",
    "    for date in df.ISO_datetime:\n",
    "        newdate = pd.to_datetime(datetime.strftime(date,'%Y-%m-%d %H:%M:%S'))\n",
    "        list.append(newdate)\n",
    "    df['datetime'] = list\n",
    "\n",
    "    df['flow_tph'] = df.flow_Lpm * 0.060\n",
    "\n",
    "    df['timestamp'] = datetime_to_timestamp(df.datetime)\n",
    "\n",
    "    df.drop(columns = ['raw_datetime', 'flow_Lpm', 'ISO_datetime'], inplace = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_pts(filename):\n",
    "    '''\n",
    "    Read PTS-2.xlsx in as a Pandas dataframe and munge for analysis\n",
    "\n",
    "    args: filename is r'PTS-2.xlsx'\n",
    "\n",
    "    returns: Pandas dataframe with datetime (local) and key coloumns of PTS data with the correct dtype\n",
    "    '''\n",
    "    df = pd.read_excel(filename)\n",
    "\n",
    "    dict = {\n",
    "        'DEPTH':'depth_m',\n",
    "        'SPEED': 'speed_mps',\n",
    "        'Cable Weight': 'cweight_kg',\n",
    "        'WHP': 'whp_barg',\n",
    "        'Temperature': 'temp_degC',\n",
    "        'Pressure': 'pressure_bara',\n",
    "        'Frequency': 'frequency_hz'\n",
    "    }\n",
    "    df.rename(columns=dict, inplace=True)\n",
    "\n",
    "    df.drop(0, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    list = []\n",
    "    for date in df.Timestamp:\n",
    "        newdate = openpyxl.utils.datetime.from_excel(date)\n",
    "        list.append(newdate)\n",
    "    df['datetime'] = list\n",
    "\n",
    "    df.drop(columns = ['Date', 'Time', 'Timestamp','Reed 0',\n",
    "       'Reed 1', 'Reed 2', 'Reed 3', 'Battery Voltage', \n",
    "       'PRT Ref Voltage','SGS Voltage', 'Internal Temp 1', \n",
    "       'Internal Temp 2', 'Internal Temp 3','Cal Temp', \n",
    "       'Error Code 1', 'Error Code 2', 'Error Code 3',\n",
    "       'Records Saved', 'Bad Pages',], inplace = True)\n",
    "    \n",
    "    df[\n",
    "        ['depth_m', 'speed_mps','cweight_kg','whp_barg','temp_degC','pressure_bara','frequency_hz']\n",
    "    ] = df[\n",
    "        ['depth_m','speed_mps','cweight_kg','whp_barg','temp_degC','pressure_bara','frequency_hz']\n",
    "        ].apply(pd.to_numeric)\n",
    "    \n",
    "    df['timestamp'] = datetime_to_timestamp(df.datetime)\n",
    "\n",
    "    return df\n",
    "\n",
    "def datetime_to_timestamp(dataframe_col):\n",
    "    '''\n",
    "    Make POSIX timestamp from Python datetime object\n",
    "\n",
    "    args: dataframe column containing datetime objects\n",
    "\n",
    "    returns: list of POSIX timestamp floats \n",
    "    '''\n",
    "    list = []\n",
    "    for date in dataframe_col:\n",
    "        timestamp = datetime.timestamp(date)\n",
    "        list.append(timestamp)\n",
    "    return list\n",
    "\n",
    "\n",
    "def timestamp_to_datetime(dataframe_col):\n",
    "    '''\n",
    "    Make Python datetime object from POSIX timestamp\n",
    "\n",
    "    args: dataframe column containing POSIX timestamps\n",
    "\n",
    "    returns: list of datetime objects \n",
    "    '''\n",
    "    list = []\n",
    "    for date in dataframe_col:\n",
    "        newdate = datetime.fromtimestamp(date)\n",
    "        list.append(newdate)\n",
    "    return list\n",
    "\n",
    "def overview_fig(pts_df,flowrate_df,title=''):\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1,figsize=(10,15),sharex=True)\n",
    "    ax1.set_title(title,y=1.1,fontsize=15)\n",
    "\n",
    "    ax1.plot(flowrate_df.datetime, flowrate_df.flow_tph, label='Surface pump flowrate', \n",
    "        c='k', linewidth=0.8, marker='.')\n",
    "    ax1.set_ylabel('Surface flowrate [t/hr]')\n",
    "    ax1.set_ylim(0,150)\n",
    "    \n",
    "    ax2.plot(pts_df.datetime, pts_df.depth_m, label='PTS tool depth', \n",
    "        c='k', linewidth=0.8)\n",
    "    ax2.set_ylabel('PTS tool depth [m]')\n",
    "    ax2.set_ylim(1000,0)\n",
    "    \n",
    "    ax3.plot(pts_df.datetime, pts_df.pressure_bara, label='PTS pressure', \n",
    "        c='tab:blue', linewidth=0.8)\n",
    "    ax3.set_ylabel('PTS pressure [bara]')\n",
    "    \n",
    "    ax4.plot(pts_df.datetime, pts_df.temp_degC, label='PTS temperature', \n",
    "        c='tab:red', linewidth=0.8)\n",
    "    ax4.set_ylabel('PTS temperature')\n",
    "    \n",
    "    ax5.plot(pts_df.datetime, pts_df.frequency_hz, label='PTS impeller frequency', \n",
    "        c='tab:green', linewidth=0.8)\n",
    "    ax5.set_ylim(-30,30)\n",
    "    ax5.set_ylabel('PTS impeller frequency [hz]')\n",
    "    # 1 hz = 60 rpm\n",
    "\n",
    "    ax6.plot(pts_df.datetime, pts_df.speed_mps, label='PTS tool speed', \n",
    "        c='tab:orange', linewidth=0.8)\n",
    "    ax6.set_ylim(-2,2)\n",
    "    ax6.set_ylabel('PTS tool speed [mps]')\n",
    "    \n",
    "    ax6.set_xlabel('Time [hh:mm]')\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "    \n",
    "    for ax in [ax1,ax2,ax3,ax4,ax5,ax6]:\n",
    "        ax.grid()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below will take a little while to run because it includes all steps required to import and munge the data (i.e., everything we did in notebook 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this method if you are running this notebook in Google Colab\n",
    "flowrate = read_flowrate(r'/content/drive/My Drive/T21-Tutoral-WellTestAnalysis-main/Data-FlowRate.xlsx')\n",
    "\n",
    "# Use this method if you are running this notebook locally (Anaconda)\n",
    "#flowrate = read_flowrate(r'Data-FlowRate.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this method if you are running this notebook in Google Colab\n",
    "pts = read_pts(r'/content/drive/My Drive/T21-Tutoral-WellTestAnalysis-main/Data-PTS.xlsx')\n",
    "\n",
    "# Use this method if you are running this notebook locally (Anaconda)\n",
    "#pts = read_pts(r'Data-PTS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pts.shape)\n",
    "pts.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Look at the data\n",
    "\n",
    "It is good practice to plot data after import so any issues are revealed. \n",
    "\n",
    "Note that the temprature logs look a little odd because they include the data aquired while the tool was held stationary for pressure monitoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(24,8),sharey=True)\n",
    "\n",
    "spinner_scatter = ax1.scatter(pts.temp_degC, pts.depth_m, c = pts.timestamp, s = 5, linewidths = 0)\n",
    "datetime_scatter = ax2.scatter(pts.datetime, pts.depth_m, c = pts.timestamp, s = 5, linewidths = 0)\n",
    "\n",
    "ax3 = ax2.twinx()\n",
    "ax3.plot(flowrate.datetime, flowrate.flow_tph, \n",
    "    c='k', linestyle = '-', linewidth = 3, alpha = 0.3, \n",
    "    label='Surface pump flowrate')\n",
    "\n",
    "ax1.set_ylabel('Depth [m]')\n",
    "ax1.set_xlabel('Temp [degC]')\n",
    "\n",
    "ax2.set_xlabel('Time [hh:mm]')\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "ax3.set_ylabel('Flowrate [t/hr]')\n",
    "\n",
    "ax1.set_ylim(1000,0)\n",
    "ax1.set_xlim(0,200)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Remove data acquired when the tool is stationary or slowing\n",
    "\n",
    "We decided that, in this case, data acquired when the tool is moving down the well at > 0.02 m/s is fast enough to be included. The reasoning behind this method is described in the notebook Bonous-filter-by-toolspeed.ipynb\n",
    " \n",
    "In the cell below, we use a Boolean expression to filter the pts dataframe. Our new working dataframe is called moving_pts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_pts = pts[\n",
    "    (pts.speed_mps > 0.9 ) & (pts.speed_mps < pts.speed_mps.max()) | \n",
    "    (pts.speed_mps > pts.speed_mps.min() ) & (pts.speed_mps < -0.9)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_pts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Extract the first heating run from the data\n",
    "\n",
    "We often want to select a single temperature log for analysis. In this example, we will extract the first heating run (i.e., the temperature log acquired after we stopped pumping into the well)\n",
    "\n",
    "We will use an interactive tool called ipywidgets to select the start and end time of our desired data range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_timestamp = pts.timestamp.iloc[0]\n",
    "max_timestamp = pts.timestamp.iloc[-1]\n",
    "\n",
    "def subselect_plot(start_value, stop_value):\n",
    "    f,ax = plt.subplots(1,1, figsize = (20,6))\n",
    "    ax.scatter(moving_pts.timestamp, moving_pts.depth_m,\n",
    "        c = 'k', s = 1, linewidths = 0, label = 'Tool depth')\n",
    "    ax1 = ax.twinx()\n",
    "    ax1.plot(flowrate.timestamp, flowrate.flow_tph, \n",
    "        ':', c='k', label='Surface pump flowrate')\n",
    "    ymin = pts.depth_m.min()\n",
    "    ymax = pts.depth_m.max() + 100\n",
    "    ax.vlines(start_value, ymin, ymax, color='tab:green')\n",
    "    ax.vlines(stop_value, ymin, ymax, color='tab:red')\n",
    "    ax.set_ylim(pts.depth_m.max() + 100, 0)\n",
    "    ax.set_xlabel('Timestamp [sec]')\n",
    "    ax.set_ylabel('Tool depth [m]')\n",
    "    ax1.set_ylabel('Flowrate [t/hr]')\n",
    "\n",
    "result = interactive(subselect_plot,\n",
    "         \n",
    "         start_value = FloatSlider\n",
    "         (\n",
    "             value = (max_timestamp - min_timestamp)/3 + min_timestamp,\n",
    "             description = 'start',\n",
    "             min = min_timestamp, \n",
    "             max = max_timestamp, \n",
    "             step = 10, \n",
    "             continuous_update=False,\n",
    "             layout = Layout(width='80%'),\n",
    "             ),\n",
    "          \n",
    "          stop_value = FloatSlider\n",
    "          (\n",
    "             value = (max_timestamp - min_timestamp)/2 + min_timestamp, \n",
    "             description = 'stop',\n",
    "             min = min_timestamp, \n",
    "             max = max_timestamp, \n",
    "             step = 10, \n",
    "             continuous_update=False,\n",
    "             layout = Layout(width='80%')\n",
    "             )\n",
    ")\n",
    "\n",
    "display(result);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make your selection\n",
    "\n",
    "Move the sliders above and then run the cell below to return the timestamp at the location of the slider. \n",
    "\n",
    "Each time you change this plot, the underlying array of data that we call with the result.children\\[x\\] statement is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'start =',result.children[0].value, ' which is', datetime.fromtimestamp(result.children[0].value), \n",
    "    '\\n stop =', result.children[1].value, ' which is', datetime.fromtimestamp(result.children[1].value),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record your analysis\n",
    "\n",
    "As part of making this process repeatable and so that it is easy to come back later to check the analysis, you need to use the range you have selected to manually define objects in the next step.\n",
    "\n",
    "Copy-paste the timestamps printed above into the cell below. They are now the objects that define the start and stop points for splicing the moving_pts dataframe. \n",
    "\n",
    "We could have defined the start and stop objects as the result.childern\\[0\\].value and result.childern\\[1\\].value objects. But if we did this, you would lose your work because these ipywidget results change every time the sliders are moved or the notebook is re-run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = 1607655784.448  # paste your start value here\n",
    "stop = 1607656174.448   # paste your stop value here\n",
    "name = 'First heating run'  # create an informative title for the data\n",
    "\n",
    "pts_first_heating_run = moving_pts[\n",
    "    (moving_pts.datetime > datetime.fromtimestamp(start)) \n",
    "    & (moving_pts.datetime < datetime.fromtimestamp(stop))\n",
    "]\n",
    "\n",
    "flowrate_first_heating_run = flowrate[\n",
    "    (flowrate.datetime > datetime.fromtimestamp(start)) \n",
    "    & (flowrate.datetime < datetime.fromtimestamp(stop))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_first_heating_run.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overview_fig function from utilities.py generates a figure that displays our data selection. \n",
    "\n",
    "Note that surface flow rate = 0 because this log is acquired after the pumps were shut off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_fig(pts_first_heating_run, flowrate_first_heating_run, title = name).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data as a csv \n",
    "\n",
    "Use the following method to export your selected data to use elsewhere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pts_first_heating_run.to_csv('Data-Temp-Heating0days.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Import and calculate contextualising data\n",
    "\n",
    "We have provided some contextualising data that:\n",
    "1. Illustrates how geothermal wells heat up over time \n",
    "2. Helps us interpret the temperature log we just extracted \n",
    "\n",
    "### 5.5.1 Stable temperature\n",
    "\n",
    "A temperature log was acquired in this well 37 days after it was drilled and tested. In this resource, it reflects the stable temperature of this well. In low permeability settings, wells may take months to fully heat after drilling and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use this method if you are running this notebook in Google Colab\n",
    "heating_37days = pd.read_csv(r'/content/drive/My Drive/T21-Tutoral-WellTestAnalysis-main/Data-Temp-Heating37days.csv') \n",
    "\n",
    "# Use this method if you are running this notebook locally (Anaconda)\n",
    "#heating_37days = pd.read_csv('Data-Temp-Heating37days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bar gauge to bar atmosphere\n",
    "\n",
    "heating_37days['pressure_bara'] = heating_37days.pres_barg - 1\n",
    "\n",
    "heating_37days.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Saturation temperature aka the boiling point for depth (BPD) curve\n",
    "\n",
    "Water will boil at a given pressure - temperature condition. We use steam tables to calculate the temperature boiling will occur given the measured pressure. This curve helps us to understand the thermodynamic conditions inside the well. \n",
    "\n",
    "The module we use to calculate the BPD is iapws and does not come standard with Anaconda. If you get a 'module not found' error, then return to the top of this notebook and run the iapws installation or pip install it into your Conda environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# note that iapws uses SI units so some unit conversion is required\n",
    "\n",
    "heating_37days['pressure_mpa'] = heating_37days.pressure_bara * 0.1  # convert pressure to MPa for ipaws\n",
    "\n",
    "pressure = heating_37days['pressure_mpa'].tolist()\n",
    "tsat = []\n",
    "for p in pressure:\n",
    "    saturation_temp = iapws.iapws97._TSat_P(p) - 273.15  # calculate saturation temp in Kelvin & convert to degC\n",
    "    tsat.append(saturation_temp)\n",
    "heating_37days['tsat_degC'] = tsat\n",
    "\n",
    "heating_37days.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.3 Well completion information\n",
    "\n",
    "Understanding where we are in the well helps us to interpret the data. This is particularly important when we seek to understand what is a process occurring inside the well and what is related to the reservoir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_shoe = 462.5 # 13 3/8 production casing shoe in meters measured depth (mMD) from the casing head flange (CHF)\n",
    "top_of_liner = 425 # top of perferated 10 3/4 liner in meters measured depth (mMD) from CHF\n",
    "terminal_depth = 946 # deepest drilled depth \n",
    "# the perferated liner is squatted on bottom but didn't quite make it all the way down (bottom of liner is 931 mMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datums and depth measurements for well test data\n",
    "\n",
    "The depth of downhole data comes in two forms: \n",
    "- Meters measured depth (mMD), which is the number of meters along the well path\n",
    "- Vertical meters (mVD), which is the number of meters in the vertical dimension \n",
    "\n",
    "It is typical for completion test data to be acquired and analysed in measured depth. However, when we seek to understand features of the reservoir, we need to also consider data in vertical depth.  \n",
    "\n",
    "There are a range of datums that are used in geothermal: \n",
    "- During drilling, most data is acquired relative to the rig floor or rotary table\n",
    "- Well test data acquired after the rig has been demobilised is typically acquired relative to the casing head flange (CHF) or the cellar top (CT), where the latter typically has a survey marker\n",
    "- Data may also be presented relative to sea level (RSL) or above sea level (ASL)\n",
    "\n",
    "It is ambiguous to define data relative to ground level (GL) because of the degree of civil construction that occurs on well pads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Visualise the data for interpretation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(10,10),sharey=True)\n",
    "\n",
    "\n",
    "ax1.set_title('All completion test temperature logs')\n",
    "\n",
    "# all temp data colored by time \n",
    "ax1.scatter(moving_pts.temp_degC, moving_pts.depth_m,     \n",
    "    c = moving_pts.timestamp, s = 5, linewidths = 0)\n",
    "\n",
    "# our sub-selected data\n",
    "ax1.plot(pts_first_heating_run.temp_degC, pts_first_heating_run.depth_m,\n",
    "    color = 'k', linestyle = ':', label = 'Our selected data')\n",
    "\n",
    "# blank well casing\n",
    "ax1.plot([1, 1],[0, production_shoe],\n",
    "    color = 'k', linewidth = 3, linestyle = '-')\n",
    "\n",
    "# perforated well casing\n",
    "ax1.plot([5, 5],[top_of_liner, terminal_depth],     \n",
    "    color = 'k', linewidth = 1.5, linestyle = '--')\n",
    "\n",
    "\n",
    "ax2.set_title('Heating (shut) temperature logs')\n",
    "\n",
    "# our sub-selected pressure + temp data\n",
    "ax2.plot(pts_first_heating_run.temp_degC, pts_first_heating_run.depth_m, \n",
    "    color ='#EBE85B', linewidth = 3, label = 'Day 0 - temp')\n",
    "\n",
    "ax2.plot(pts_first_heating_run.pressure_bara, pts_first_heating_run.depth_m, \n",
    "    linestyle = '--', linewidth = 3, color = '#EBE85B', label = 'Day 0 - pres')\n",
    "\n",
    "# stable pressure + temp data\n",
    "ax2.plot(heating_37days.temp_degC, heating_37days.depth_m, \n",
    "    color = 'k', label = 'Day 37 - temp')\n",
    "\n",
    "ax2.plot(heating_37days.pressure_bara, heating_37days.depth_m, \n",
    "    linestyle = '--', color = 'k', label = 'Day 37 - pres')\n",
    "\n",
    "# saturation temp for the stable pressure\n",
    "ax2.plot(heating_37days.tsat_degC, heating_37days.depth_m, \n",
    "    linestyle = ':', color = 'k', label = 'Day 37 - BPD')\n",
    "\n",
    "\n",
    "ax1.set_ylim(1000,0) \n",
    "ax1.set_ylabel('Depth [m]')\n",
    "ax1.set_xlim(0,200)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.legend()\n",
    "ax2.set_xlim(0,300)\n",
    "\n",
    "for ax in [ax1,ax2]:\n",
    "    ax.set_xlabel('Temperature [degC] or Pressure [bara]')\n",
    "    ax.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temperature in our case study well\n",
    "\n",
    "This is not a course on how to read temperature logs. However, we can make a couple of quick observations of these data. \n",
    "\n",
    "- The injecting temperature profiles are a completely different shape from the heating (shut) profiles. This illustrates the importance of knowing what the well condition was when the temperature log was acquired (i.e., shut, injection, flowing, bleed).\n",
    "- The two heating (shut) profiles have a completely different shape. This illustrates how important it is to know _when_ the temperature log was acquired relative to operations that impact well temprature (i.e., drilling, injection testing or quenching, flowing, etc). \n",
    "- It is heating up the most rapidly just below 700 mMD where two-phase fluid is entering the well. \n",
    "- The 37-day heating profile is on the BPD profile from 450-600 mMD, so we would expect two-phase conditions there. The BPD used is for pure water and may not be exact. Below 600 mMD we expect that the well is compressed liquid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Â© 2021 [Irene Wallis](https://www.cubicearth.nz/) and [Katie McLean](https://www.linkedin.com/in/katie-mclean-25994315/) \n",
    "\n",
    "Licensed under the Apache License, Version 2.0\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geothrm",
   "language": "python",
   "name": "geothrm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
